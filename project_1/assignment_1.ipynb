{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0538ab5-ba7f-4b41-aa2b-9598e588f8e6",
   "metadata": {},
   "source": [
    "# CS 7641 Machine Learning - Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b6f579-9953-4407-8163-d3b321ed75e4",
   "metadata": {},
   "source": [
    "## 1. Abstract\n",
    "\n",
    "This assignment will focus on some techniques in supervised learning, and their performance across different scenarios. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed293d-b3d3-431b-a685-b8e4899416fb",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "\n",
    "Five learning algorithms will be tested and compared:\n",
    "- Decision trees with some form of pruning\n",
    "- Neural networks\n",
    "- Boosting\n",
    "- Support Vector Machines\n",
    "- k-nearest neighbors\n",
    "\n",
    "I will use implementation from `sklearn` package to run the learning process and only compare the results. Even though I will not implement any code, I will explain the selection of function and its implementation briefly, as well as the selection parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2aa54b-3c80-4054-ab94-dcc9390a607d",
   "metadata": {},
   "source": [
    "## 3. Dataset\n",
    "\n",
    "For this project, I selected the following datasets:\n",
    "- [Check Loan Eligibility](https://www.kaggle.com/datasets/mukeshmanral/check-loan-eligibility)\n",
    "- [Student Performance (Math only)](https://www.kaggle.com/datasets/whenamancodes/student-performance)\n",
    "\n",
    "The loan eligibility data set is a set of processed data for modeling the eligibility check, based on features like gender, education, income, loan amount, credit history, etc. It consists of 12 columns, of which 10 are integer columns (binary) and 2 are decimal columns. It has a clear `y` column named `Loan_Status`. I have evaluated it from a ethical perspective in another course at OMSCS (AI Ethics) and it is an interesting data set to evaluate historical biases as well. Therefore, I would like to use it for the ML algorithms and see if different algorithms will induce different biases towards different groups.\n",
    "\n",
    "The student performance data set was drawn from student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. I have only selected the data of the Math subject. The data was specifically modeled under binary/five-level classification and regression tasks. Interesting point about this data set is that it includes three potential `y` columns: G1, G2, G3, corresponding to 1st, 2nd and 3rd period grades. However, the G2 is dependent on G1, and G3 is dependent on both G1 and G2. I find that it could be useful for Bayesian analysis in the future. Therefore, I would like to use it for the ML course as it is versatile and easy to implement for multiple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be4e6d-8fe5-48c9-b662-b0b24fd0b831",
   "metadata": {},
   "source": [
    "## 4. Method\n",
    "\n",
    "The implementation methods will be briefly introduced in the following section, but many details will be skipped since it is available on `sklearn` [documentation page](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a50e6b-29b4-4355-a350-ecb13cb4622b",
   "metadata": {},
   "source": [
    "### 4.1 Decision trees with some form of pruning\n",
    "\n",
    "I selected the implemented algorithm from `sklearn.tree.DecisionTreeClassifier`, which has the training part as well as the pruning method (`cost_complexity_pruning_path`). By default, it uses [GINI (see reference for calculation)](https://en.wikipedia.org/wiki/Gini_coefficient) as the criterion to measure the quality of a split. It uses `best` as its strategy to choose the split at each node so that we make sure to pick the attribute with the best GINI coefficient.\n",
    "\n",
    "Detailed code in file clf_tree.py.\n",
    "\n",
    "\n",
    "Current tree has 209 nodes, with alpha: 0\n",
    "Train score 1.0\n",
    "Test score 0.7402597402597403\n",
    "\n",
    "Current tree has 11 nodes, with alpha: 0.005\n",
    "Train score 0.808695652173913\n",
    "Test score 0.8311688311688312\n",
    "\n",
    "Current tree has 21 nodes, with alpha: 0\n",
    "Train score 1.0\n",
    "Test score 0.9494949494949495\n",
    "\n",
    "Current tree has 5 nodes, with alpha: 0.012\n",
    "Train score 0.9662162162162162\n",
    "Test score 0.9696969696969697\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6473a-e4c1-46fb-9ad4-a3e1cb6ef8d6",
   "metadata": {},
   "source": [
    "### 4.2 Neural networks\n",
    "\n",
    "I selected the implemented algorithm from `sklearn.neural_network.MLPClassifier`. By default, it limits hidden layer size to 100, which is what I will use here. I selected \"logistic\" as its `activation` parameter, which uses the logistic sigmoid function we discussed in class. \n",
    "\n",
    "Detailed code in file neural.py.\n",
    "\n",
    "Train score 0.6934782608695652\n",
    "Test score 0.7272727272727273\n",
    "\n",
    "\n",
    "Train score 0.956081081081081\n",
    "Test score 0.9292929292929293\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b90073-5185-497d-b337-2b1c95bd8edf",
   "metadata": {},
   "source": [
    "### 4.3 Boosting with Bagging\n",
    "\n",
    "I selected the implemented algorithm from `sklearn.ensemble.BaggingClassifier` as my boosting algorithm for the decision tree model. I selected parameters `max_samples=0.3`, `max_features=0.8` so that for each individual model to be bagged, it will sample 30% of the data and 80% of the features to be considered. \n",
    "\n",
    "Detailed code in file bagged.py.\n",
    "\n",
    "Train score 0.808695652173913\n",
    "Test score 0.8246753246753247\n",
    "Train score 0.9662162162162162\n",
    "Test score 0.9696969696969697\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeeb7c7-41d8-498c-b103-5dd152744ffc",
   "metadata": {},
   "source": [
    "### 4.4 Support Vector Machines\n",
    "\n",
    "I selected the implemented algorithm from `sklearn.svm.SVC` as my SVM algorithm. I selected parameter `gamma='scale'` for ingesting the gamma values to the kernel functions. Other parameters will be kept at default values. For the kernel functions, I will use `‘rbf’`and `‘sigmoid’` to test the model performance.\n",
    "\n",
    "Detailed code in file svm.py.\n",
    "\n",
    "Train score 0.808695652173913\n",
    "Test score 0.8246753246753247\n",
    "Train score 0.9662162162162162\n",
    "Test score 0.9696969696969697\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc7130-3760-4cf4-8030-f2fdf7d51bf9",
   "metadata": {},
   "source": [
    "### 4.5 k-Nearest Neighbors\n",
    "\n",
    "I selected the implemented algorithm from `sklearn.neighbors.KNeighborsClassifier` \n",
    "\n",
    "Detailed code in file knn.py.\n",
    "\n",
    "Train score 0.808695652173913\n",
    "Test score 0.8246753246753247\n",
    "Train score 0.9662162162162162\n",
    "Test score 0.9696969696969697\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0d0c6-042a-4a09-916a-c9ecbe3641b9",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b84866f-0525-4d58-ab64-69017a156e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Method how I conduct my experiments\n",
    "\n",
    "Experiment discussion on my base learning/validation curves and my learning curve with tuned parameters\n",
    "\n",
    "wall clock time, discuss what I observed\n",
    "\n",
    "summary what I observed from my experiments\n",
    "\n",
    "reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
